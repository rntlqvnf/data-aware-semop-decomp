# configs/config.yaml

# LLM μ„λΉ„μ¤ κ΄€λ ¨ μ„¤μ •
llm:
  # π’΅ μ‚¬μ©ν•  μ„λΉ„μ¤λ¥Ό μ„ νƒν•λ” λ§μ¤ν„° μ¤μ„μΉ ('openai' λλ” 'azure_openai')
  provider: "openai"

  # 1. ν‘μ¤€ OpenAI API μ„¤μ •
  openai:
    # OpenAI ν”λ«νΌμ—μ„ μ‚¬μ©ν•λ” λ¨λΈ μ΄λ¦„
    model: "gpt-4o"

  # 2. Azure OpenAI API μ„¤μ •
  azure_openai:
    # Azure Portalμ—μ„ ν™•μΈν• λ°°ν¬ μ΄λ¦„(Deployment Name)
    deployment_name: "gpt-4o" 
    api_version: "2024-05-01-preview"

  # LLM λ¨λΈ μƒμ„± νλΌλ―Έν„°
  generation_params:
    max_tokens: 4096
    temperature: 0.5
    # top_p, frequency_penalty λ“± κΈ°νƒ€ νλΌλ―Έν„° μ¶”κ°€ κ°€λ¥

# Planner λ¨λ“ κ΄€λ ¨ μ„¤μ •
planner:
  llm_system_prompt: "You are an expert AI Planner for the DWSemDcmp framework."
  decomposition_params:
    num_strategies_to_generate: 3

  caching:
    # trueλ΅ μ„¤μ •ν•λ©΄, λ™μΌν• operator_promptμ— λ€ν•΄ LLMμ„ λ‹¤μ‹ νΈμ¶ν•μ§€ μ•κ³  μ €μ¥λ κ²°κ³Όλ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.
    enabled: true
    # LLM μ‘λ‹µμ„ μ €μ¥ν•  μΊμ‹ νμΌμ κ²½λ΅
    cache_file: "logs/llm_strategy_cache.json"

  visualization:
    enabled: true # trueλ΅ μ„¤μ •ν•λ©΄, LLMμ΄ μƒμ„±ν• μ „λµμ„ μ½μ†”μ— μ‹κ°ν™”ν•μ—¬ μ¶λ ¥ν•©λ‹λ‹¤.

# μƒν”λ§ λ‹¨κ³„ κ΄€λ ¨ μ„¤μ •
sampling:
  size: 100