# configs/config.yaml

# LLM ì„œë¹„ìŠ¤ ê´€ë ¨ ì„¤ì •
llm:
  # ğŸ’¡ ì‚¬ìš©í•  ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ë§ˆìŠ¤í„° ìŠ¤ìœ„ì¹˜ ('openai' ë˜ëŠ” 'azure_openai')
  provider: "azure_openai"

  # 1. í‘œì¤€ OpenAI API ì„¤ì •
  openai:
    # OpenAI í”Œë«í¼ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ì´ë¦„
    model: "gpt-4o"

  # 2. Azure OpenAI API ì„¤ì •
  azure_openai:
    # Azure Portalì—ì„œ í™•ì¸í•œ ë°°í¬ ì´ë¦„(Deployment Name)
    deployment_name: "gpt-4o" 
    api_version: "2024-05-01-preview"

  # LLM ëª¨ë¸ ìƒì„± íŒŒë¼ë¯¸í„°
  generation_params:
    max_tokens: 4096
    temperature: 0.5
    # top_p, frequency_penalty ë“± ê¸°íƒ€ íŒŒë¼ë¯¸í„° ì¶”ê°€ ê°€ëŠ¥

# Planner ëª¨ë“ˆ ê´€ë ¨ ì„¤ì •
planner:
  llm_system_prompt: "You are an expert AI Planner for the DWSemDcmp framework."
  decomposition_params:
    num_strategies_to_generate: 3

  caching:
    # trueë¡œ ì„¤ì •í•˜ë©´, ë™ì¼í•œ operator_promptì— ëŒ€í•´ LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì €ì¥ëœ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    enabled: true
    # LLM ì‘ë‹µì„ ì €ì¥í•  ìºì‹œ íŒŒì¼ì˜ ê²½ë¡œ
    cache_file: "logs/llm_strategy_cache.json"

  visualization:
    enabled: true # trueë¡œ ì„¤ì •í•˜ë©´, LLMì´ ìƒì„±í•œ ì „ëµì„ ì½˜ì†”ì— ì‹œê°í™”í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

# Router ëª¨ë“ˆ ê´€ë ¨ ì„¤ì •
router:
  # ë¼ìš°íŒ… ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤.
  # 'auto': KnowledgeBaseì˜ í†µê³„ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ ìµœì  Planì„ ì„ íƒí•©ë‹ˆë‹¤.
  # 'human': ê° ë°ì´í„° ì•„ì´í…œë§ˆë‹¤ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì–´ë–¤ Planì„ ì‹¤í–‰í• ì§€ ë¬»ìŠµë‹ˆë‹¤. (í…ŒìŠ¤íŠ¸ìš©)
  routing_mode: "human"

# ìƒ˜í”Œë§ ë‹¨ê³„ ê´€ë ¨ ì„¤ì •
sampling:
  size: 100