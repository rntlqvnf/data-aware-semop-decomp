- name: DecodeImage
  description: "Converts a binary-encoded image (e.g., JPEG, PNG) into a usable PIL.Image object."
  modality: image
  inputs:
    - { name: "binary_image", type: "bytes" }
  outputs:
    - { name: "image_object", type: "PIL.Image" }
  implementations:
    - implementation_name: "Pillow_Decode"
      source: "local_python"
      metrics: { latency_ms: 0.5, cost_usd_per_image: 0.0, accuracy: 1.0, vram_mb: 50 }

- name: ResizeImage
  description: "Resizes the input image to the specified target size. Commonly used to match model input dimensions."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
    - { name: "target_size", type: "Tuple[int, int]" }
  outputs:
    - { name: "resized_image", type: "PIL.Image" }
  implementations:
    - implementation_name: "Pillow_Resize_Lanczos"
      source: "local_python"
      metrics: { latency_ms: 0.2, cost_usd_per_image: 0.0, accuracy: 1.0, vram_mb: 100 }

- name: AssessClarity
  description: "Evaluates the sharpness or blurriness of the image. Returns a score between 0.0 (very blurry) and 1.0 (very clear)."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "clarity_score", type: "float" }
  implementations:
    - implementation_name: "OpenCV_Laplacian_Variance"
      source: "local_opencv"
      metrics: { latency_ms: 5, cost_usd_per_image: 0.0, accuracy: 0.95, vram_mb: 50 }

- name: DenoiseImage
  description: "Removes visual noise from the image to improve quality."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "denoised_image", type: "PIL.Image" }
  implementations:
    - implementation_name: "OpenCV_FastNlMeans"
      source: "local_opencv"
      metrics: { latency_ms: 15, cost_usd_per_image: 0.0, accuracy: 0.85, vram_mb: 200 }
    - implementation_name: "DnCNN_PyTorch"
      source: "local_pytorch"
      metrics: { latency_ms: 4, cost_usd_per_image: 0.0, accuracy: 0.95, vram_mb: 4500 }

- name: GetImageEmbedding
  description: "Encodes the image into a high-dimensional embedding vector for semantic comparison."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "embedding_vector", type: "numpy.ndarray" }
  implementations:
    - implementation_name: "CLIP-ViT-B-32"
      source: "huggingface_hub"
      metrics: { latency_ms: 4, cost_usd_per_image: 0.0, accuracy: 0.88, vram_mb: 3500 }
    - implementation_name: "SigLIP-S-14"
      source: "huggingface_hub"
      metrics: { latency_ms: 2, cost_usd_per_image: 0.0, accuracy: 0.91, vram_mb: 1600 }
    - implementation_name: "Azure_Vectorize_Image"
      source: "azure_ai_vision"
      metrics: { latency_ms: 250, cost_usd_per_image: 0.0001, accuracy: 0.95, vram_mb: 0 }

- name: DetectObjects
  description: "Detects all objects in the image and returns their bounding boxes and label names."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "detected_objects", type: "List[Dict]", desc: "Each object must have 'label' and 'box'. Example: [{'label': 'table', 'box': [x1, y1, x2, y2]}, ...]" }
  implementations:
    - implementation_name: "YOLOv8-S"
      source: "local_pytorch"
      metrics: { latency_ms: 15, cost_usd_per_image: 0.0, accuracy: 0.85, vram_mb: 2800 }
    - implementation_name: "YOLOv8-X"
      source: "local_pytorch"
      metrics: { latency_ms: 50, cost_usd_per_image: 0.0, accuracy: 0.92, vram_mb: 7500 }

- name: ReadTextFromImage
  description: "Extracts printed or handwritten text from the image using OCR."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "extracted_text", type: "str" }
  implementations:
    - implementation_name: "EasyOCR"
      source: "local_python"
      metrics: { latency_ms: 100, cost_usd_per_image: 0.0, accuracy: 0.80, vram_mb: 2000 }
    - implementation_name: "Azure_Read_API"
      source: "azure_ai_vision"
      metrics: { latency_ms: 500, cost_usd_per_image: 0.0015, accuracy: 0.96, vram_mb: 0 }

- name: GetImageCaption
  description: "Generates a natural language caption that describes the overall content of the image."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
  outputs:
    - { name: "caption_text", type: "str" }
  implementations:
    - implementation_name: "BLIP-2-FlanT5-XL"
      source: "huggingface_hub"
      metrics: { latency_ms: 35, cost_usd_per_image: 0.0, accuracy: 0.89, vram_mb: 11000 }
    - implementation_name: "Azure_Describe_API"
      source: "azure_ai_vision"
      metrics: { latency_ms: 600, cost_usd_per_image: 0.0015, accuracy: 0.94, vram_mb: 0 }

- name: AnswerQuestionAboutImage
  description: "Answers natural language questions about the image content (VQA)."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
    - { name: "question_text", type: "str" }
  outputs:
    - { name: "answer_text", type: "str" }
  implementations:
    - implementation_name: "LLaVA-1.5-7B"
      source: "local_pytorch"
      metrics: { latency_ms: 120, cost_usd_per_image: 0.0, accuracy: 0.85, vram_mb: 16000 }
    - implementation_name: "GPT-4o_Azure"
      source: "azure_openai"
      metrics: { latency_ms: 1500, cost_usd_per_image: 0.005, accuracy: 0.98, vram_mb: 0 }
    - implementation_name: "GPT-4o_OpenAI"
      source: "openai_api"
      metrics: { latency_ms: 1500, cost_usd_per_image: 0.005, accuracy: 0.98, vram_mb: 0 }

- name: GenerateImageFromText
  description: "Generates a new image based on a text prompt."
  modality: image
  inputs:
    - { name: "prompt_text", type: "str" }
  outputs:
    - { name: "generated_image", type: "PIL.Image" }
  implementations:
    - implementation_name: "SDXL-Turbo"
      source: "local_pytorch"
      metrics: { latency_ms: 800, cost_usd_per_image: 0.0, accuracy: 0.80, vram_mb: 9000 }
    - implementation_name: "DALL-E-3"
      source: "azure_openai"
      metrics: { latency_ms: 7000, cost_usd_per_image: 0.04, accuracy: 0.95, vram_mb: 0 }
    - implementation_name: "DALL-E-3_OpenAI"
      source: "openai_api"
      metrics: { latency_ms: 7000, cost_usd_per_image: 0.04, accuracy: 0.95, vram_mb: 0 }

- name: UpscaleImage
  description: "Improves the resolution of a low-resolution image (Super Resolution)."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
    - { name: "scale_factor", type: "int" }
  outputs:
    - { name: "upscaled_image", type: "PIL.Image" }
  implementations:
    - implementation_name: "ESRGAN-x4"
      source: "local_pytorch"
      metrics: { latency_ms: 220, cost_usd_per_image: 0.0, accuracy: 0.90, vram_mb: 2800 }

- name: CropToObject
  description: "Crops the input image to the specified bounding box of the target object."
  modality: image
  inputs:
    - { name: "image_object", type: "PIL.Image" }
    - { name: "bounding_box", type: "List[int]", desc: "[x1, y1, x2, y2]" }
  outputs:
    - { name: "cropped_image", type: "PIL.Image" }
  implementations:
    - implementation_name: "Pillow_Crop"
      source: "local_python"
      metrics: { latency_ms: 1, cost_usd_per_image: 0.0, accuracy: 1.0, vram_mb: 10 }